{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "anomaly-title",
   "metadata": {},
   "source": [
    "# Nevada Procurement: Anomaly Detection Analysis\n",
    "\n",
    "**Objective**: Identify potential anomalies, outliers, and data quality issues in Nevada procurement data using statistical methods.\n",
    "\n",
    "**Data**: Nevada procurement contracts and purchase orders silver data\n",
    "\n",
    "**Key Methods**:\n",
    "- Statistical outlier detection (Z-score analysis)\n",
    "- Benford's Law testing for fraud detection\n",
    "- Data integrity checks (date validity, amount consistency)\n",
    "- Split purchase analysis\n",
    "\n",
    "**Coverage**: Contracts (49.8%), Purchase Orders (5.2%) - use with appropriate caveats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "setup",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import duckdb\n",
    "from scipy import stats\n",
    "from scipy.stats import chisquare\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configure plotting\n",
    "plt.style.use('default')\n",
    "sns.set_palette('husl')\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "\n",
    "print(\"Setup complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load-data",
   "metadata": {},
   "outputs": [],
   "source": "# Load data for anomaly detection\nconn = duckdb.connect()\n\n# Load contracts data\ncontracts_query = \"\"\"\nSELECT \n    contract_id,\n    vendor_name,\n    organization,\n    fiscal_year_begin,\n    dollars_spent_to_date,\n    begin_date,\n    end_date,\n    contract_duration_days,\n    daily_spend_rate,\n    is_zero_spend,\n    contract_status\nFROM read_parquet(\"../../data/silver/contracts/version=v0.3.0/*/data.parquet\")\nWHERE contract_id IS NOT NULL\n\"\"\"\n\ncontracts = conn.execute(contracts_query).df()\nprint(f\"Loaded {len(contracts):,} contract records\")\nprint(f\"Zero spend contracts: {contracts['is_zero_spend'].sum()} ({contracts['is_zero_spend'].mean()*100:.1f}%)\")\nprint(f\"Total spend: ${contracts['dollars_spent_to_date'].sum():,.2f}\")\n\n# Load purchase orders data\npos_query = \"\"\"\nSELECT \n    po_id,\n    vendor_name,\n    organization,\n    fiscal_year,\n    sent_date,\n    total_amount,\n    revision_number,\n    status_category\nFROM read_parquet(\"../../data/silver/purchase_orders/version=v0.5.0/*/data.parquet\")\nWHERE po_id IS NOT NULL\n\"\"\"\n\npos = conn.execute(pos_query).df()\nprint(f\"\\nLoaded {len(pos):,} purchase order records\")\nprint(f\"Total PO amount: ${pos['total_amount'].sum():,.2f}\")\nprint(f\"Revisions: {(pos['revision_number'] > 0).sum()} ({(pos['revision_number'] > 0).mean()*100:.1f}%)\")\n\ncontracts.head()"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "outlier-detection",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistical Outlier Detection\n",
    "print(\"=== STATISTICAL OUTLIER ANALYSIS ===\")\n",
    "\n",
    "# Contract amount outliers (exclude zero spend)\n",
    "non_zero_contracts = contracts[contracts['dollars_spent_to_date'] > 0]\n",
    "if len(non_zero_contracts) > 0:\n",
    "    amounts = non_zero_contracts['dollars_spent_to_date']\n",
    "    z_scores = np.abs(stats.zscore(amounts))\n",
    "    outliers = non_zero_contracts[z_scores > 3]\n",
    "    \n",
    "    print(f\"Contract amount outliers (|z| > 3): {len(outliers)} / {len(non_zero_contracts)} ({len(outliers)/len(non_zero_contracts)*100:.1f}%)\")\n",
    "    \n",
    "    if len(outliers) > 0:\n",
    "        print(\"\\nTop Amount Outliers:\")\n",
    "        outlier_cols = ['contract_id', 'vendor_name', 'organization', 'dollars_spent_to_date']\n",
    "        top_outliers = outliers.nlargest(5, 'dollars_spent_to_date')[outlier_cols]\n",
    "        for _, row in top_outliers.iterrows():\n",
    "            print(f\"  {row['contract_id']}: ${row['dollars_spent_to_date']:,.2f} ({row['vendor_name'][:30]}...)\")\n",
    "\n",
    "# Duration outliers\n",
    "duration_data = contracts[contracts['contract_duration_days'] > 0]\n",
    "if len(duration_data) > 0:\n",
    "    duration_z = np.abs(stats.zscore(duration_data['contract_duration_days']))\n",
    "    duration_outliers = duration_data[duration_z > 3]\n",
    "    \n",
    "    print(f\"\\nDuration outliers: {len(duration_outliers)} contracts\")\n",
    "    if len(duration_outliers) > 0:\n",
    "        print(f\"Longest contract: {duration_outliers['contract_duration_days'].max()} days\")\n",
    "        print(f\"Shortest outlier: {duration_outliers['contract_duration_days'].min()} days\")\n",
    "\n",
    "# Daily spend rate outliers\n",
    "daily_spend_data = contracts[contracts['daily_spend_rate'] > 0]\n",
    "if len(daily_spend_data) > 0:\n",
    "    daily_z = np.abs(stats.zscore(daily_spend_data['daily_spend_rate']))\n",
    "    daily_outliers = daily_spend_data[daily_z > 3]\n",
    "    \n",
    "    print(f\"\\nDaily spend rate outliers: {len(daily_outliers)} contracts\")\n",
    "    if len(daily_outliers) > 0:\n",
    "        print(f\"Highest daily rate: ${daily_outliers['daily_spend_rate'].max():,.2f}/day\")\n",
    "\n",
    "print(f\"\\nOverall outlier summary:\")\n",
    "print(f\"Amount outliers: {len(outliers) if len(non_zero_contracts) > 0 else 0}\")\n",
    "print(f\"Duration outliers: {len(duration_outliers) if len(duration_data) > 0 else 0}\")\n",
    "print(f\"Daily rate outliers: {len(daily_outliers) if len(daily_spend_data) > 0 else 0}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "benford-analysis",
   "metadata": {},
   "outputs": [],
   "source": "# Benford's Law Analysis for Fraud Detection\ndef benford_test(amounts, name=\"Dataset\"):\n    \"\"\"Test if amounts follow Benford's Law distribution\"\"\"\n    # Filter positive amounts only\n    amounts = amounts[amounts > 0]\n    \n    if len(amounts) < 100:\n        return {\"name\": name, \"n\": len(amounts), \"warning\": \"Sample too small for Benford test\"}\n    \n    # Extract first digits\n    first_digits = amounts.astype(str).str[0].astype(int)\n    \n    # Observed frequencies\n    observed_counts = first_digits.value_counts().reindex(range(1, 10), fill_value=0)\n    observed = observed_counts / len(amounts)\n    \n    # Expected Benford frequencies\n    expected = np.array([np.log10(1 + 1/d) for d in range(1, 10)])\n    \n    # Ensure observed and expected sum to same value for chi-square test\n    expected_counts = expected * len(amounts)\n    \n    # Chi-square test with proper normalization\n    try:\n        chi_stat, p_value = chisquare(observed_counts, expected_counts)\n    except ValueError:\n        # If normalization issues, use manual calculation\n        chi_stat = sum((observed_counts - expected_counts)**2 / expected_counts)\n        from scipy.stats import chi2\n        p_value = 1 - chi2.cdf(chi_stat, df=8)  # 8 degrees of freedom (9 digits - 1)\n    \n    return {\n        \"name\": name,\n        \"n\": len(amounts),\n        \"chi_stat\": chi_stat,\n        \"p_value\": p_value,\n        \"anomaly_flag\": p_value < 0.05,\n        \"observed\": observed,\n        \"expected\": expected\n    }\n\nprint(\"=== BENFORD'S LAW ANALYSIS ===\")\n\n# Test contract amounts\ncontract_benford = benford_test(contracts['dollars_spent_to_date'], \"Contract Amounts\")\nprint(f\"Contract amounts (n={contract_benford['n']})\")\nif 'warning' in contract_benford:\n    print(f\"  Warning: {contract_benford['warning']}\")\nelse:\n    print(f\"  Chi-square: {contract_benford['chi_stat']:.3f}, p-value: {contract_benford['p_value']:.3f}\")\n    print(f\"  Anomaly flag: {contract_benford['anomaly_flag']} (p < 0.05 indicates potential manipulation)\")\n\n# Test PO amounts\npo_benford = benford_test(pos['total_amount'], \"Purchase Order Amounts\")\nprint(f\"\\nPurchase order amounts (n={po_benford['n']})\")\nif 'warning' in po_benford:\n    print(f\"  Warning: {po_benford['warning']}\")\nelse:\n    print(f\"  Chi-square: {po_benford['chi_stat']:.3f}, p-value: {po_benford['p_value']:.3f}\")\n    print(f\"  Anomaly flag: {po_benford['anomaly_flag']}\")\n\n# Visualize Benford distribution if enough data\nif 'observed' in contract_benford:\n    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n    \n    # Contract amounts\n    digits = range(1, 10)\n    ax1.bar(digits, contract_benford['observed'], alpha=0.7, label='Observed')\n    ax1.plot(digits, contract_benford['expected'], 'ro-', label='Benford Expected')\n    ax1.set_xlabel('First Digit')\n    ax1.set_ylabel('Frequency')\n    ax1.set_title('Contract Amounts vs Benford\\'s Law')\n    ax1.legend()\n    ax1.set_xticks(digits)\n    \n    # PO amounts if enough data\n    if 'observed' in po_benford:\n        ax2.bar(digits, po_benford['observed'], alpha=0.7, label='Observed')\n        ax2.plot(digits, po_benford['expected'], 'ro-', label='Benford Expected')\n        ax2.set_xlabel('First Digit')\n        ax2.set_ylabel('Frequency')\n        ax2.set_title('Purchase Order Amounts vs Benford\\'s Law')\n        ax2.legend()\n        ax2.set_xticks(digits)\n    \n    plt.tight_layout()\n    plt.show()"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "data-integrity",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Integrity Checks\n",
    "print(\"=== DATA INTEGRITY ANALYSIS ===\")\n",
    "\n",
    "# Date validity checks\n",
    "date_issues = contracts[\n",
    "    (contracts['begin_date'].notna() & contracts['end_date'].notna()) &\n",
    "    (contracts['end_date'] < contracts['begin_date'])\n",
    "]\n",
    "print(f\"Contracts with end_date < begin_date: {len(date_issues)}\")\n",
    "\n",
    "# Negative amounts\n",
    "negative_contracts = contracts[contracts['dollars_spent_to_date'] < 0]\n",
    "negative_pos = pos[pos['total_amount'] < 0]\n",
    "print(f\"Contracts with negative spend: {len(negative_contracts)}\")\n",
    "print(f\"POs with negative amounts: {len(negative_pos)}\")\n",
    "\n",
    "# Duration consistency\n",
    "duration_check = contracts[\n",
    "    (contracts['begin_date'].notna() & contracts['end_date'].notna() & \n",
    "     contracts['contract_duration_days'].notna())\n",
    "]\n",
    "if len(duration_check) > 0:\n",
    "    duration_check = duration_check.copy()\n",
    "    duration_check['calculated_duration'] = (duration_check['end_date'] - duration_check['begin_date']).dt.days\n",
    "    duration_check['duration_diff'] = abs(duration_check['calculated_duration'] - duration_check['contract_duration_days'])\n",
    "    \n",
    "    duration_mismatches = duration_check[duration_check['duration_diff'] > 5]  # Allow 5-day tolerance\n",
    "    print(f\"Duration mismatches (>5 days): {len(duration_mismatches)} / {len(duration_check)} ({len(duration_mismatches)/len(duration_check)*100:.1f}%)\")\n",
    "\n",
    "# Missing critical fields\n",
    "print(f\"\\nMissing data analysis:\")\n",
    "print(f\"Contracts missing vendor_name: {contracts['vendor_name'].isna().sum()}\")\n",
    "print(f\"Contracts missing organization: {contracts['organization'].isna().sum()}\")\n",
    "print(f\"POs missing vendor_name: {pos['vendor_name'].isna().sum()}\")\n",
    "print(f\"POs missing sent_date: {pos['sent_date'].isna().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "split-purchase-detection",
   "metadata": {},
   "outputs": [],
   "source": "# Split Purchase Detection\nprint(\"=== SPLIT PURCHASE ANALYSIS ===\")\n\n# Look for multiple POs to same vendor on same day with similar amounts\nsplit_query = \"\"\"\nWITH same_day_vendor AS (\n    SELECT \n        vendor_name,\n        organization,\n        sent_date,\n        COUNT(*) as po_count,\n        SUM(total_amount) as total_amount,\n        AVG(total_amount) as avg_amount,\n        STDDEV(total_amount) as stddev_amount,\n        MIN(total_amount) as min_amount,\n        MAX(total_amount) as max_amount\n    FROM read_parquet(\"../../data/silver/purchase_orders/version=v0.5.0/*/data.parquet\")\n    WHERE vendor_name IS NOT NULL \n        AND sent_date IS NOT NULL\n        AND total_amount > 0\n    GROUP BY vendor_name, organization, sent_date\n    HAVING COUNT(*) > 1\n)\nSELECT *,\n    CASE \n        WHEN stddev_amount / avg_amount < 0.1 THEN 'Similar amounts'\n        WHEN max_amount / min_amount < 2.0 THEN 'Close amounts' \n        ELSE 'Varied amounts'\n    END as amount_pattern\nFROM same_day_vendor\nWHERE po_count >= 2\nORDER BY po_count DESC, total_amount DESC\n\"\"\"\n\nsplit_results = conn.execute(split_query).df()\nprint(f\"Same-day, same-vendor PO groups: {len(split_results)}\")\n\nif len(split_results) > 0:\n    # Flag potential split purchases\n    potential_splits = split_results[\n        (split_results['amount_pattern'].isin(['Similar amounts', 'Close amounts'])) &\n        (split_results['po_count'] >= 2)\n    ]\n    \n    print(f\"Potential split purchases: {len(potential_splits)}\")\n    if len(potential_splits) > 0:\n        print(\"\\nTop Potential Split Purchase Patterns:\")\n        split_cols = ['vendor_name', 'organization', 'sent_date', 'po_count', 'total_amount', 'amount_pattern']\n        print(potential_splits[split_cols].head().to_string(index=False))\n\n# Weekend/holiday PO analysis\npos_with_dates = pos[pos['sent_date'].notna()].copy()\nif len(pos_with_dates) > 0:\n    pos_with_dates['weekday'] = pos_with_dates['sent_date'].dt.dayofweek\n    weekend_pos = pos_with_dates[pos_with_dates['weekday'].isin([5, 6])]  # Saturday, Sunday\n    \n    print(f\"\\nWeekend POs: {len(weekend_pos)} / {len(pos_with_dates)} ({len(weekend_pos)/len(pos_with_dates)*100:.1f}%)\")\n    if len(weekend_pos) > 0:\n        print(f\"Weekend PO total: ${weekend_pos['total_amount'].sum():,.2f}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "visualizations",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create anomaly visualizations\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "fig.suptitle('Nevada Procurement: Anomaly Detection Analysis', fontsize=16, y=0.98)\n",
    "\n",
    "# 1. Amount distribution with outliers\n",
    "if len(non_zero_contracts) > 0:\n",
    "    log_amounts = np.log10(non_zero_contracts['dollars_spent_to_date'])\n",
    "    axes[0, 0].hist(log_amounts, bins=30, alpha=0.7, edgecolor='black')\n",
    "    if len(outliers) > 0:\n",
    "        outlier_log = np.log10(outliers['dollars_spent_to_date'])\n",
    "        axes[0, 0].hist(outlier_log, bins=30, alpha=0.8, color='red', edgecolor='black', label=f'Outliers (n={len(outliers)})')\n",
    "        axes[0, 0].legend()\n",
    "    axes[0, 0].set_xlabel('Log10(Contract Amount)')\n",
    "    axes[0, 0].set_ylabel('Frequency')\n",
    "    axes[0, 0].set_title('Contract Amount Distribution (Log Scale)')\n",
    "\n",
    "# 2. Daily spend rate vs contract amount\n",
    "if len(daily_spend_data) > 0:\n",
    "    axes[0, 1].scatter(daily_spend_data['dollars_spent_to_date'], \n",
    "                      daily_spend_data['daily_spend_rate'], alpha=0.6)\n",
    "    if len(daily_outliers) > 0:\n",
    "        axes[0, 1].scatter(daily_outliers['dollars_spent_to_date'], \n",
    "                          daily_outliers['daily_spend_rate'], \n",
    "                          color='red', s=50, alpha=0.8, label=f'Outliers (n={len(daily_outliers)})')\n",
    "        axes[0, 1].legend()\n",
    "    axes[0, 1].set_xlabel('Total Contract Amount')\n",
    "    axes[0, 1].set_ylabel('Daily Spend Rate')\n",
    "    axes[0, 1].set_title('Daily Spend Rate vs Contract Amount')\n",
    "    axes[0, 1].set_xscale('log')\n",
    "    axes[0, 1].set_yscale('log')\n",
    "\n",
    "# 3. PO revision patterns\n",
    "if len(pos) > 0:\n",
    "    revision_counts = pos['revision_number'].value_counts().sort_index()\n",
    "    revision_counts.plot(kind='bar', ax=axes[1, 0], alpha=0.7)\n",
    "    axes[1, 0].set_xlabel('Revision Number')\n",
    "    axes[1, 0].set_ylabel('Count')\n",
    "    axes[1, 0].set_title('Purchase Order Revision Distribution')\n",
    "    axes[1, 0].tick_params(axis='x', rotation=0)\n",
    "\n",
    "# 4. Temporal patterns (POs by day of week)\n",
    "if len(pos_with_dates) > 0:\n",
    "    day_names = ['Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat', 'Sun']\n",
    "    daily_counts = pos_with_dates['weekday'].value_counts().sort_index()\n",
    "    daily_counts.index = [day_names[i] for i in daily_counts.index]\n",
    "    daily_counts.plot(kind='bar', ax=axes[1, 1], alpha=0.7)\n",
    "    axes[1, 1].set_xlabel('Day of Week')\n",
    "    axes[1, 1].set_ylabel('PO Count')\n",
    "    axes[1, 1].set_title('Purchase Orders by Day of Week')\n",
    "    axes[1, 1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Save the figure\n",
    "plt.savefig('../output/anomaly_detection_analysis.png', dpi=300, bbox_inches='tight')\n",
    "print(\"Charts saved to ../output/anomaly_detection_analysis.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "export-results",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export anomaly detection results\n",
    "if len(non_zero_contracts) > 0 and len(outliers) > 0:\n",
    "    outliers.to_csv('../output/amount_outliers.csv', index=False)\n",
    "\n",
    "if len(split_results) > 0:\n",
    "    split_results.to_csv('../output/potential_split_purchases.csv', index=False)\n",
    "\n",
    "if len(date_issues) > 0:\n",
    "    date_issues.to_csv('../output/date_integrity_issues.csv', index=False)\n",
    "\n",
    "# Anomaly summary\n",
    "anomaly_summary = {\n",
    "    'analysis_date': pd.Timestamp.now().strftime('%Y-%m-%d'),\n",
    "    'contracts_analyzed': len(contracts),\n",
    "    'pos_analyzed': len(pos),\n",
    "    'amount_outliers': len(outliers) if len(non_zero_contracts) > 0 else 0,\n",
    "    'duration_outliers': len(duration_outliers) if len(duration_data) > 0 else 0,\n",
    "    'daily_rate_outliers': len(daily_outliers) if len(daily_spend_data) > 0 else 0,\n",
    "    'date_integrity_issues': len(date_issues),\n",
    "    'potential_split_purchases': len(potential_splits) if len(split_results) > 0 else 0,\n",
    "    'weekend_pos': len(weekend_pos) if len(pos_with_dates) > 0 else 0,\n",
    "    'contract_benford_pvalue': contract_benford.get('p_value'),\n",
    "    'contract_benford_anomaly': contract_benford.get('anomaly_flag'),\n",
    "    'po_benford_pvalue': po_benford.get('p_value'),\n",
    "    'po_benford_anomaly': po_benford.get('anomaly_flag')\n",
    "}\n",
    "\n",
    "pd.Series(anomaly_summary).to_csv('../output/anomaly_summary.csv')\n",
    "\n",
    "print(\"Anomaly detection results exported:\")\n",
    "print(\"  - amount_outliers.csv\")\n",
    "print(\"  - potential_split_purchases.csv\")\n",
    "print(\"  - date_integrity_issues.csv\")\n",
    "print(\"  - anomaly_summary.csv\")\n",
    "print(\"  - anomaly_detection_analysis.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conclusions",
   "metadata": {},
   "source": [
    "## Key Findings & Audit Implications\n",
    "\n",
    "**Statistical Outliers**: [To be filled after running analysis]\n",
    "\n",
    "**Benford's Law Results**: Tests for potential data manipulation in amount distributions\n",
    "\n",
    "**Data Quality Issues**: Integrity checks reveal data consistency problems\n",
    "\n",
    "**Audit Recommendations**:\n",
    "- Investigate high-value outliers for approval compliance\n",
    "- Review potential split purchases for threshold avoidance\n",
    "- Validate weekend/holiday transactions for policy compliance\n",
    "- Address data integrity issues in source systems\n",
    "\n",
    "**Methodology Notes**:\n",
    "- Z-score threshold of 3 for outlier detection (99.7% confidence)\n",
    "- Benford's Law requires >100 observations for reliability\n",
    "- Split purchase detection uses same-day, same-vendor heuristics\n",
    "- Coverage limitations: PO analysis (5.2%) has high variance"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}